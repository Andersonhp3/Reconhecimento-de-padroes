{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tic-tac-toe2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyWPr56RwoHAX3XW/0Cwfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andersonhp3/Reconhecimento-de-padroes/blob/main/tic_tac_toe2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9wOyy58693p"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from sklearn.metrics.cluster import v_measure_score\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import pairwise_distances,cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_text\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_uWjRZ17i6b"
      },
      "source": [
        "## **Carregando base com atributos categóricos**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGc3Aotl7xOy"
      },
      "source": [
        "TTT = pd.read_csv('tic-tac-toe.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFnQzFc3VvXr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "z3XajR4q-BiQ",
        "outputId": "d8853476-cb51-4eb6-96c8-6ea3f42b0dcf"
      },
      "source": [
        "TTT.describe(include=\"all\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tfs</th>\n",
              "      <th>tms</th>\n",
              "      <th>trs</th>\n",
              "      <th>mls</th>\n",
              "      <th>mds</th>\n",
              "      <th>mrs</th>\n",
              "      <th>bls</th>\n",
              "      <th>bms</th>\n",
              "      <th>brs</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "      <td>958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>418</td>\n",
              "      <td>378</td>\n",
              "      <td>418</td>\n",
              "      <td>378</td>\n",
              "      <td>458</td>\n",
              "      <td>378</td>\n",
              "      <td>418</td>\n",
              "      <td>378</td>\n",
              "      <td>418</td>\n",
              "      <td>626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        tfs  tms  trs  mls  mds  mrs  bls  bms  brs     class\n",
              "count   958  958  958  958  958  958  958  958  958       958\n",
              "unique    3    3    3    3    3    3    3    3    3         2\n",
              "top       x    x    x    x    x    x    x    x    x  positive\n",
              "freq    418  378  418  378  458  378  418  378  418       626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZpRZMFmPNmA"
      },
      "source": [
        "# **Utilizando One Hot Enconder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "BGJhsQkWPYj_",
        "outputId": "6968ddeb-40bb-47a7-eada-c4baca1027c0"
      },
      "source": [
        "TTT = pd.get_dummies(TTT, columns=[\"tfs\", \"tms\", \"trs\", \"mls\", \"mds\", \"mrs\", \"bls\", \"bms\", \"brs\"], prefix=[\"tfs\", \"tms\", \"trs\", \"mls\", \"mds\", \"mrs\", \"bls\", \"bms\", \"brs\"])\n",
        "TTT\n",
        "y = TTT.iloc[:, 0]\n",
        "TTT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>tfs_b</th>\n",
              "      <th>tfs_o</th>\n",
              "      <th>tfs_x</th>\n",
              "      <th>tms_b</th>\n",
              "      <th>tms_o</th>\n",
              "      <th>tms_x</th>\n",
              "      <th>trs_b</th>\n",
              "      <th>trs_o</th>\n",
              "      <th>trs_x</th>\n",
              "      <th>mls_b</th>\n",
              "      <th>mls_o</th>\n",
              "      <th>mls_x</th>\n",
              "      <th>mds_b</th>\n",
              "      <th>mds_o</th>\n",
              "      <th>mds_x</th>\n",
              "      <th>mrs_b</th>\n",
              "      <th>mrs_o</th>\n",
              "      <th>mrs_x</th>\n",
              "      <th>bls_b</th>\n",
              "      <th>bls_o</th>\n",
              "      <th>bls_x</th>\n",
              "      <th>bms_b</th>\n",
              "      <th>bms_o</th>\n",
              "      <th>bms_x</th>\n",
              "      <th>brs_b</th>\n",
              "      <th>brs_o</th>\n",
              "      <th>brs_x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958 rows × 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        class  tfs_b  tfs_o  tfs_x  tms_b  ...  bms_o  bms_x  brs_b  brs_o  brs_x\n",
              "0    positive      0      0      1      0  ...      1      0      0      1      0\n",
              "1    positive      0      0      1      0  ...      0      1      0      1      0\n",
              "2    positive      0      0      1      0  ...      1      0      0      0      1\n",
              "3    positive      0      0      1      0  ...      0      0      1      0      0\n",
              "4    positive      0      0      1      0  ...      1      0      1      0      0\n",
              "..        ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "953  negative      0      1      0      0  ...      0      1      0      0      1\n",
              "954  negative      0      1      0      0  ...      1      0      0      0      1\n",
              "955  negative      0      1      0      0  ...      1      0      0      0      1\n",
              "956  negative      0      1      0      0  ...      1      0      0      0      1\n",
              "957  negative      0      1      0      0  ...      0      1      0      0      1\n",
              "\n",
              "[958 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb1-ErEPdCrH",
        "outputId": "39e4dfc9-e038-46f2-a350-a41e1be330e9"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder  \n",
        "atributo = ['class']\n",
        "enc = OrdinalEncoder()\n",
        "enc.fit(TTT[atributo])\n",
        "TTT[atributo] = enc.transform(TTT[atributo])\n",
        "y = TTT.iloc[:, 0]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "      ... \n",
              "953    0.0\n",
              "954    0.0\n",
              "955    0.0\n",
              "956    0.0\n",
              "957    0.0\n",
              "Name: class, Length: 958, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VW2FpJoCrVb"
      },
      "source": [
        "# **Padronização**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gteSjMpkCl_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "640eb9e2-6009-4c70-bfd4-c433910a109f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "atributos = [\"tfs_b\",\"tfs_o\",\"tfs_x\",\"tms_b\",\"tms_o\",\"tms_x\",\"trs_b\",\"trs_o\",\"trs_x\",\"mls_b\",\"mls_o\",\"mls_x\",\"mds_b\",\"mds_o\",\"mds_x\",\"mrs_b\",\"mrs_o\",\"mrs_x\",\"bls_b\",\"bls_o\",\"bls_x\",\"bms_b\",\"bms_o\",\"bms_x\",\"brs_b\",\"brs_o\",\"brs_x\"]\n",
        "X = StandardScaler().fit_transform(TTT[atributos])\n",
        "X = pd.DataFrame(X)\n",
        "X\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>1.916552</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>1.916552</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>1.916552</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>953</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>958 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2   ...        24        25        26\n",
              "0   -0.52177 -0.733294  1.136603  ... -0.521770  1.363709 -0.879815\n",
              "1   -0.52177 -0.733294  1.136603  ... -0.521770  1.363709 -0.879815\n",
              "2   -0.52177 -0.733294  1.136603  ... -0.521770 -0.733294  1.136603\n",
              "3   -0.52177 -0.733294  1.136603  ...  1.916552 -0.733294 -0.879815\n",
              "4   -0.52177 -0.733294  1.136603  ...  1.916552 -0.733294 -0.879815\n",
              "..       ...       ...       ...  ...       ...       ...       ...\n",
              "953 -0.52177  1.363709 -0.879815  ... -0.521770 -0.733294  1.136603\n",
              "954 -0.52177  1.363709 -0.879815  ... -0.521770 -0.733294  1.136603\n",
              "955 -0.52177  1.363709 -0.879815  ... -0.521770 -0.733294  1.136603\n",
              "956 -0.52177  1.363709 -0.879815  ... -0.521770 -0.733294  1.136603\n",
              "957 -0.52177  1.363709 -0.879815  ... -0.521770 -0.733294  1.136603\n",
              "\n",
              "[958 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-RvCvB77P-L"
      },
      "source": [
        "# **Avaliando com Holdout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "x-dhlB6Y7TcD",
        "outputId": "c6dfb6c3-1373-438d-cb54-83f5cdb91f7b"
      },
      "source": [
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_treino"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>1.916552</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>1.916552</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.521770</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>-0.741729</td>\n",
              "      <td>1.044846</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>1.916552</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>-0.879815</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>1.238706</td>\n",
              "      <td>-0.447774</td>\n",
              "      <td>1.348201</td>\n",
              "      <td>-0.957079</td>\n",
              "      <td>-0.594228</td>\n",
              "      <td>1.379504</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>-0.733294</td>\n",
              "      <td>1.136603</td>\n",
              "      <td>1.682855</td>\n",
              "      <td>-0.724898</td>\n",
              "      <td>-0.807294</td>\n",
              "      <td>-0.52177</td>\n",
              "      <td>1.363709</td>\n",
              "      <td>-0.879815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>670 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2   ...       24        25        26\n",
              "228 -0.52177 -0.733294  1.136603  ... -0.52177  1.363709 -0.879815\n",
              "319 -0.52177  1.363709 -0.879815  ... -0.52177  1.363709 -0.879815\n",
              "715 -0.52177 -0.733294  1.136603  ... -0.52177  1.363709 -0.879815\n",
              "212 -0.52177 -0.733294  1.136603  ... -0.52177 -0.733294  1.136603\n",
              "79  -0.52177 -0.733294  1.136603  ... -0.52177  1.363709 -0.879815\n",
              "..       ...       ...       ...  ...      ...       ...       ...\n",
              "106 -0.52177 -0.733294  1.136603  ... -0.52177 -0.733294  1.136603\n",
              "270 -0.52177 -0.733294  1.136603  ... -0.52177 -0.733294  1.136603\n",
              "860 -0.52177  1.363709 -0.879815  ... -0.52177 -0.733294  1.136603\n",
              "435 -0.52177  1.363709 -0.879815  ... -0.52177 -0.733294  1.136603\n",
              "102 -0.52177 -0.733294  1.136603  ... -0.52177  1.363709 -0.879815\n",
              "\n",
              "[670 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWyQPc0G9LPD",
        "outputId": "36206128-417e-4d14-e466-b14ef36392de"
      },
      "source": [
        "mlp = MLPClassifier(activation=\"relu\", hidden_layer_sizes=(10,))\n",
        "mlp.fit(X_treino, y_treino)\n",
        "mlp.predict(X_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
              "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldtYWuMc-AHb"
      },
      "source": [
        "# **Processando com Kfold**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PqsP5A69_xi",
        "outputId": "37d0db46-8b08-47fd-989d-86b787ac4f5b"
      },
      "source": [
        "resultados = []\n",
        "kf = KFold(n_splits=10, shuffle=True)\n",
        "for index_treino, index_teste in kf.split(X):\n",
        "    X_treino, X_teste = X.iloc[index_treino], X.iloc[index_teste]\n",
        "    y_treino, y_teste = y.iloc[index_treino], y.iloc[index_teste]\n",
        "    mlp.fit(X_treino, y_treino)\n",
        "    resultados.append(mlp.predict(X_teste))\n",
        "resultados"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.]),\n",
              " array([1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
              "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1lOxZmu_ULi"
      },
      "source": [
        "# **Pratica do projeto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKMvGd7So5G0"
      },
      "source": [
        "**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcMsI9PR_XQL",
        "outputId": "da6f3ecc-d318-4620-dc7d-b753e11ce3ef"
      },
      "source": [
        "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "valores_k = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
        "resultados_knn = []\n",
        "\n",
        "for k in valores_k:\n",
        "    resultados_k = []\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    kf = KFold(n_splits=10, shuffle=True)\n",
        "    for index_train, index_valid in kf.split(X_treino):\n",
        "        X_train, X_validacao = X_treino.iloc[index_train], X_treino.iloc[index_valid]\n",
        "        y_train, y_validacao = y_treino.iloc[index_train], y_treino.iloc[index_valid]\n",
        "        knn.fit(X_train, y_train)\n",
        "        resultados_k.append(knn.score(X_validacao, y_validacao))\n",
        "    resultados_knn.append(sum(resultados_k)/len(resultados_k))\n",
        "resultados_knn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7776119402985076,\n",
              " 0.7611940298507464,\n",
              " 0.744776119402985,\n",
              " 0.7417910447761195,\n",
              " 0.7701492537313432,\n",
              " 0.7895522388059703,\n",
              " 0.835820895522388,\n",
              " 0.8567164179104477,\n",
              " 0.8820895522388058,\n",
              " 0.9253731343283581,\n",
              " 0.9283582089552238,\n",
              " 0.9283582089552237,\n",
              " 0.9,\n",
              " 0.9,\n",
              " 0.8582089552238805]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG4uLWNs_h80",
        "outputId": "730d14f3-2a98-4d43-f08f-0d0ad9945126"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=11)\n",
        "knn.fit(X_treino, y_treino)\n",
        "knn.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9027777777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYPq-rmh_km8",
        "outputId": "301e815a-d92a-46e6-e69f-c367e780b3c3"
      },
      "source": [
        "y_pred = knn.predict(X_teste)\n",
        "\n",
        "precision_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9366515837104072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FciqTGj_odz",
        "outputId": "cc023078-e7fa-47c2-e2ec-f0f9d2bc4b7f"
      },
      "source": [
        "recall_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8526315789473684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB9dq_9G_qdN",
        "outputId": "295b22c7-f619-437c-c945-960121fc4e5b"
      },
      "source": [
        "f1_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8797638217928073"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK2FmVqto8cL"
      },
      "source": [
        "**SVM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8kaKJfj_s37",
        "outputId": "3312884d-0423-45b3-e8dd-a21e786c2fc2"
      },
      "source": [
        "valores_kernel = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
        "resultados_svm = []\n",
        "\n",
        "for kernel in valores_kernel:\n",
        "    resultados_kernel = []\n",
        "    svc = SVC(kernel=kernel)\n",
        "    kf = KFold(n_splits=10, shuffle=True)\n",
        "    for index_train, index_valid in kf.split(X_treino):\n",
        "        X_train, X_validacao = X_treino.iloc[index_train], X_treino.iloc[index_valid]\n",
        "        y_train, y_validacao = y_treino.iloc[index_train], y_treino.iloc[index_valid]\n",
        "        svc.fit(X_train, y_train)\n",
        "        resultados_kernel.append(svc.score(X_validacao, y_validacao))\n",
        "    resultados_svm.append(sum(resultados_kernel)/len(resultados_kernel))\n",
        "resultados_svm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9850746268656717,\n",
              " 0.9850746268656716,\n",
              " 0.9552238805970148,\n",
              " 0.8074626865671644]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwRO_K27_yOj",
        "outputId": "12900bae-cf7a-4bc3-d3c5-8bd4ce80b91a"
      },
      "source": [
        "svc = SVC(kernel=\"poly\")\n",
        "svc.fit(X_treino, y_treino)\n",
        "svc.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9895833333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOPnRGi5cMg5",
        "outputId": "9889156f-43bf-4679-f0da-f0b5ecb8198d"
      },
      "source": [
        "y_pred = svc.predict(X_teste)\n",
        "\n",
        "precision_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9923469387755102"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z2Muxr1cdMY",
        "outputId": "2c35b861-6845-407a-bbad-4ea8ef3b317b"
      },
      "source": [
        "recall_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9842105263157894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVsOttSHcio5",
        "outputId": "09b8f833-a0f7-456d-aa20-6e91382dc125"
      },
      "source": [
        "f1_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9881225684945631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmB36U_oqyKr"
      },
      "source": [
        "**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRHIxszoqz-t",
        "outputId": "e1be2235-1b2e-40ef-8dd0-00a441636975"
      },
      "source": [
        "valores_ativacao = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
        "resultados_mlp = []\n",
        "\n",
        "for ativacao in valores_ativacao:\n",
        "    resultados_ativacao = []\n",
        "    mlp = MLPClassifier(activation=ativacao)\n",
        "    kf = KFold(n_splits=10, shuffle=True)\n",
        "    for index_train, index_valid in kf.split(X_treino):\n",
        "        X_train, X_validacao = X_treino.iloc[index_train], X_treino.iloc[index_valid]\n",
        "        y_train, y_validacao = y_treino.iloc[index_train], y_treino.iloc[index_valid]\n",
        "        mlp.fit(X_train, y_train)\n",
        "        resultados_ativacao.append(svc.score(X_validacao, y_validacao))\n",
        "    resultados_mlp.append(sum(resultados_ativacao)/len(resultados_ativacao))\n",
        "resultados_mlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9910447761194028, 0.991044776119403, 0.991044776119403, 0.9910447761194028]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791b6662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba295d17-f66e-4dba-c9c3-457c45e77c30"
      },
      "source": [
        "#como os valores foram iguais/empataram escolhir um deles.para obter a curacia de..\n",
        "mlp = MLPClassifier(activation=\"logistic\")\n",
        "mlp.fit(X_treino, y_treino)\n",
        "mlp.score(X_teste, y_teste)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9791666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5SXLPF2rvAM",
        "outputId": "50d5048d-5790-4a49-a492-7cb4c5895399"
      },
      "source": [
        "y_pred = mlp.predict(X_teste)\n",
        "\n",
        "precision_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9849246231155779"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs7VdEQzrzhz",
        "outputId": "6b77d916-1d4d-469b-cb59-9b0eb927c520"
      },
      "source": [
        "recall_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.968421052631579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvyDkXXnr3G8",
        "outputId": "da359eb2-5708-49aa-a56c-230f2309501f"
      },
      "source": [
        "f1_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9760425909494232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvaiUMaQr8v0"
      },
      "source": [
        "**navebays**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4EJE09or3F7",
        "outputId": "e1f5695d-939d-4a1d-e87e-f1c4f144e54b"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "gnb.fit(X_treino, y_treino)\n",
        "gnb.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6597222222222222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cis6ed7TsDQ1",
        "outputId": "1db3a8d5-3c2e-46a1-96af-4514caf6a6ee"
      },
      "source": [
        "y_pred = gnb.predict(X_teste)\n",
        "\n",
        "precision_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6226385636221702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-CMuViqsDPk",
        "outputId": "75c6af4a-157c-43f5-ca25-3286fcaaef9f"
      },
      "source": [
        "recall_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6285246795745841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B7AllgBsHKj",
        "outputId": "7567dc5f-0b01-4935-b3c7-e51b651f0fcc"
      },
      "source": [
        "f1_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6246808510638298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI9jCelPvpfd"
      },
      "source": [
        "**Arvore**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf482d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46164b55-e686-425d-fee8-cc6bda25ec24"
      },
      "source": [
        "arvore = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "arvore.fit(X_treino, y_treino)\n",
        "arvore.score(X_teste, y_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9340277777777778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e78540c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bdceec-5338-45d4-aa36-d849d5346821"
      },
      "source": [
        "y_pred = arvore.predict(X_teste)\n",
        "\n",
        "precision_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9228249194414608"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4eeafcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737c6e21-9b45-4286-d208-c0bdebdb14a9"
      },
      "source": [
        "recall_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9293973275156804"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f520f835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e57216b-b746-461d-cf19-75d55412a5af"
      },
      "source": [
        "f1_score(y_teste, y_pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9259730245268469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    }
  ]
}